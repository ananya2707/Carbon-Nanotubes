# Carbon-Nanotubes
Carbon Nanotubes Using Machine Learning Regression Models

1. Introduction
Carbon nanotubes (CNTs) are cylindrical nanostructures renowned for their outstanding mechanical, electrical, and thermal properties, positioning them as highly promising materials in diverse fields like nanoelectronics, sensors, and composites. These properties are intricately linked to the atomic arrangement within the CNT lattice. Accurately predicting CNT atomic coordinates is thus pivotal for customizing their properties to suit specific applications. However, this prediction is challenging due to the complex interplay of factors such as tube diameter, chirality, and length.
Machine learning (ML) has emerged as a powerful tool for predicting material properties and atomic structures in nanomaterials research. ML algorithms can analyze large datasets of atomic structures and properties to identify patterns and make predictions. In this study, we propose a novel approach for predicting the atomic coordinates of CNTs using ML regression models. We aim to develop a predictive model that can accurately predict CNT atomic coordinates based on a set of input parameters, such as tube diameter, chirality, and length.
The main objective of this research is to demonstrate the feasibility and effectiveness of using ML regression models for predicting CNT atomic coordinates. To achieve this objective, we will first construct a dataset of known CNT structures with their corresponding atomic coordinates. Next, we will train and evaluate several ML regression models, including linear regression, support vector regression, and random forest regression, to predict CNT atomic coordinates based on the input parameters. We will compare the performance of these models in terms of prediction accuracy and computational efficiency.
This research is expected to provide valuable insights into the use of ML regression models for predicting atomic coordinates of CNTs, which can facilitate the design and development of CNT-based materials with tailored properties for various applications. Additionally, the developed predictive model can serve as a valuable tool for researchers and engineers working in the field of nanomaterials design and characterization.


4 Experimental Analysis
 Experimental analysis of models involves evaluating the performance of various machine learning regression models, such as linear regression, decision tree regression, support vector regression (SVR), and RANSAC, on the dataset of carbon nanotubes. This analysis typically includes splitting the dataset into training and testing sets, training each model on the training set, and then evaluating its performance on the testing set using metrics like mean squared error (MSE) and R-squared value. The goal of this analysis is to determine which model performs best in predicting atomic coordinates based on the chiral vector and initial atomic coordinates.
 ![image](https://github.com/user-attachments/assets/8fd659d0-2a39-4dbb-aa3a-f44192510b98)
It compares R2 score and MSE across regression models, aiming to assess their predictive accuracy for predicting atomic coordinates based on the chiral vector and initial atomic coordinates. This analysis helps identify the most effective models for calculated atomic coordinates of carbon nanotube.

5 Evaluation
The evaluation of the models based on the provided values shows that all four models perform quite well in terms of accuracy and R-squared score. However, there are some differences in their performance.
●	Linear Regression and RANSAC: Both models have almost identical performance, with a very high training accuracy of approximately 99.98% and a slightly lower but still impressive test accuracy of around 99.76%. The R-squared score is also very high at approximately 0.9976, indicating that these models explain a large portion of the variance in the data. The mean squared error (MSE) is also very low at around 0.000206, suggesting that these models make accurate predictions with minimal error.
●	Decision Tree Regression: The decision tree model performs slightly better than linear regression and RANSAC in terms of test accuracy, with a value of approximately 99.75%. The training accuracy is perfect at 100%, indicating that the model may be overfitting the training data. However, the R-squared score and MSE are similar to the other models, suggesting that it still provides a good fit to the data.
●	Support Vector Regression (SVR)*: SVR has the lowest performance among the four models, with a training accuracy of approximately 95.27% and a test accuracy of around 95.22%. The R-squared score and MSE are also lower compared to the other models, indicating that SVR may not explain as much variance in the data and may have higher prediction errors.
